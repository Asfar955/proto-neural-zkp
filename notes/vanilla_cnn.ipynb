{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5c490d4",
   "metadata": {},
   "source": [
    "# Vanilla CNN implementation with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "794b9914-cce9-4d71-b20d-96df96f6403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c3349aa-434a-4c9b-a451-feeb341aaa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(input, f):\n",
    "    \"\"\"\n",
    "    Evaluate the output of a convolutional layer using the filter f.\n",
    "    input.shape = (h, w, c)\n",
    "    f.shape = (c_out, hf, wf, c_in)\n",
    "    \"\"\"\n",
    "    h, w, c = input.shape\n",
    "    c_out, hf, wf, c_in = f.shape\n",
    "\n",
    "    assert c == c_in, \"Input channels must match!\"\n",
    "    assert hf%2 == 1, \"Height of the filter (f.shape[1]) must be an uneven number!\"\n",
    "    assert wf%2 == 1, \"Width of the filter (f.shape[2]) must be an uneven number!\"\n",
    "\n",
    "    # unilateral width and heght\n",
    "    dh = hf//2\n",
    "    dw = wf//2\n",
    "\n",
    "    # after convolution dw and dh get substracted from all sides of the image, c_out is number of convolutions which dictates # of channels\n",
    "    # initialize matrix with 0s\n",
    "    output = np.zeros(shape=(h-2*dh, w-2*dw, c_out))\n",
    "\n",
    "# run convolution\n",
    "# go over image height - kernel padding (2*dh)\n",
    "    for i in range(dh, h-dh):\n",
    "        # go over image width - kernel padding (2*dw)\n",
    "        for j in range(dw, w-dw):\n",
    "            # kernel slice\n",
    "            a = input[i-dh:i+dh+1, j-dw:j+dw+1]\n",
    "            for k in range(c_out):\n",
    "                # filter channel 1..c_out\n",
    "                b = f[k,:,:,:]\n",
    "                # apply filter\n",
    "                output[i-dh, j-dw, k] = (a*b).sum() # a.size multiplication\n",
    "    \n",
    "    n_params = f.size\n",
    "    n_multiplications = a.size * c_out * (w-2*dw) * (h-2*dh)\n",
    "    name = f\"conv {'x'.join([str(e) for e in f.shape])}\"\n",
    "    \n",
    "    return output, n_params, n_multiplications, name\n",
    "\n",
    "\n",
    "def relu_layer(input):    \n",
    "    output = input.copy()\n",
    "    output[output<0] = 0\n",
    "    \n",
    "    n_params = 0\n",
    "    n_multiplications = input.size\n",
    "    \n",
    "    return output, n_params, n_multiplications, \"relu\"\n",
    "\n",
    "\n",
    "def max_pooling_layer(input, s):\n",
    "    \"\"\"\n",
    "    Apply max pooling layer using a sxs patch.\n",
    "    \"\"\"\n",
    "    h, w, c = input.shape\n",
    "\n",
    "    assert h%s == 0, \"Height must be divisible by s!\"\n",
    "    assert w%s == 0, \"Width must be dibisible by s!\"\n",
    "\n",
    "    output = np.zeros(shape=(h//s, w//s, c))\n",
    "\n",
    "    for i in range(0, h, s):\n",
    "        for j in range(0, w, s):\n",
    "            for k in range(c):\n",
    "                a = input[i:i+s, j:j+s, k]\n",
    "                output[i//s, j//s, k] = a.max()\n",
    "    \n",
    "    n_params = 0\n",
    "    n_multiplications = input.size\n",
    "    return output, n_params, n_multiplications, \"max-pool\"\n",
    "\n",
    "\n",
    "def flatten_layer(input):\n",
    "    output = input.flatten()\n",
    "    n_params = 0\n",
    "    n_multiplications = 0\n",
    "    return output, n_params, n_multiplications, \"flatten\"\n",
    "\n",
    "\n",
    "def fully_connected_layer(input, weights, biases):\n",
    "    \"\"\"\n",
    "    Evaluate the output of a fully connected layer.\n",
    "    input.shape = (output_dim)\n",
    "    weights.shape = (output_dim, input_dim)\n",
    "    f.shape = (output_dim)\n",
    "    \"\"\"\n",
    "    assert input.ndim == 1, \"Input must be a flattend array!\"\n",
    "    assert weights.shape[1] == input.shape[0], \"Input shapes must match!\"\n",
    "    assert weights.shape[0] == biases.shape[0], \"Output shapes must match!\"\n",
    "\n",
    "    output = np.dot(weights, input) + biases\n",
    "    \n",
    "    n_params = weights.size + biases.size\n",
    "    n_multiplications = weights.size\n",
    "    name = f\"full {'x'.join([str(e) for e in weights.shape])}\"\n",
    "    \n",
    "    return output, n_params, n_multiplications, name\n",
    "\n",
    "\n",
    "def normalize(input):\n",
    "    output = input / np.linalg.norm(input)\n",
    "    n_params = 0\n",
    "    n_multiplications = 1 + input.size\n",
    "    return output, n_params, n_multiplications, \"normalize\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6355fd9a-0b61-46ff-8efc-a6888f0e2b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               layer |    output shape |     #parameters |            #ops \n",
      "-------------------- | --------------- | --------------- | --------------- \n",
      "       conv 32x5x5x3 |   (116, 76, 32) |            2400 |        21158400 \n",
      "            max-pool |    (58, 38, 32) |               0 |          282112 \n",
      "                relu |    (58, 38, 32) |               0 |           70528 \n",
      "      conv 32x5x5x32 |    (54, 34, 32) |           25600 |        47001600 \n",
      "            max-pool |    (27, 17, 32) |               0 |           58752 \n",
      "                relu |    (27, 17, 32) |               0 |           14688 \n",
      "             flatten |        (14688,) |               0 |               0 \n",
      "     full 1000x14688 |         (1000,) |        14689000 |        14688000 \n",
      "                relu |         (1000,) |               0 |            1000 \n",
      "1000\n",
      "         full 5x1000 |            (5,) |            5005 |            5000 \n",
      "\n",
      "final output: [ -9404869. -11033050. -34374361. -20396580.  70483360.]\n",
      "           normalize |            (5,) |               0 |               6 \n",
      "\n",
      "final output: [-0.11425511 -0.13403508 -0.41759714 -0.24778798  0.85626755]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "\n",
    "p = \"{:>20} | {:>15} | {:>15} | {:>15} \"\n",
    "print(p.format(\"layer\", \"output shape\", \"#parameters\", \"#ops\"))\n",
    "print(p.format(\"-\"*20, \"-\"*15, \"-\"*15, \"-\"*15))\n",
    "\n",
    "# input\n",
    "x = np.random.randint(low=-5, high=5, size=(120,80,3))\n",
    "\n",
    "# conv layer\n",
    "f = np.random.randint(low=-10, high=+10, size=(32,5,5,3)) \n",
    "x, n_params, n_multiplications, name = conv_layer(x, f)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "# max pooling\n",
    "x, n_params, n_multiplications, name =  max_pooling_layer(x, 2)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "# relu layer\n",
    "x, n_params, n_multiplications, name = relu_layer(x)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "# conv layer\n",
    "f = np.random.randint(low=-10, high=+10, size=(32,5,5,32)) \n",
    "x, n_params, n_multiplications, name = conv_layer(x, f)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "# max pooling\n",
    "x, n_params, n_multiplications, name =  max_pooling_layer(x, 2)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "# relu layer\n",
    "x, n_params, n_multiplications, name = relu_layer(x)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "# flatten\n",
    "x, n_params, n_multiplications, name =  flatten_layer(x)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "# fully connected\n",
    "weights = np.random.randint(low=-10, high=+10, size=(1000, x.shape[0])) \n",
    "biases = np.random.randint(low=-10, high=+10, size=(1000)) \n",
    "x, n_params, n_multiplications, name = fully_connected_layer(x, weights, biases)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "# relu layer\n",
    "x, n_params, n_multiplications, name = relu_layer(x)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "# fully connected\n",
    "weights = np.random.randint(low=-10, high=+10, size=(5, x.shape[0])) \n",
    "biases = np.random.randint(low=-10, high=+10, size=(5)) \n",
    "x, n_params, n_multiplications, name = fully_connected_layer(x, weights, biases)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "assert(np.isclose(x, [ -9404869, -11033050, -34374361, -20396580,  70483360.]).all())\n",
    "\n",
    "print(\"\\nfinal output:\", x)\n",
    "\n",
    "# normalization\n",
    "x, n_params, n_multiplications, name = normalize(x)\n",
    "print(p.format(name, str(x.shape), n_params, n_multiplications))\n",
    "\n",
    "print(\"\\nfinal output:\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c065d3-e68b-4a63-9e7e-237dbf704819",
   "metadata": {},
   "source": [
    "# JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201f02e1-0951-4247-be82-05a290c35d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from json import JSONEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d147d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d97c695a-f706-401f-b85c-b46396a8c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "\n",
    "shape = (3,3,3)\n",
    "x = np.random.randint(low=-5, high=5, size=shape)\n",
    "\n",
    "x = x.flatten()\n",
    "\n",
    "# Serialization\n",
    "data = {\n",
    "    \"v\": 1,\n",
    "    \"dim\": shape,\n",
    "    \"data\": x\n",
    "    }\n",
    "\n",
    "json_data = json.dumps(data, cls=NumpyArrayEncoder)\n",
    "\n",
    "with open(\"../src/json/test.json\", \"w\") as f:\n",
    "    f.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3395de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (120,80,3)\n",
    "\n",
    "initial = np.random.randint(low=-5, high=5, size=shape).astype(np.float32, copy=False).flatten()\n",
    "\n",
    "data = {\n",
    "    \"v\": 1,\n",
    "    \"dim\": shape,\n",
    "    \"data\": initial\n",
    "    }\n",
    "\n",
    "json_data = json.dumps(data, cls=NumpyArrayEncoder)\n",
    "\n",
    "layers_json = {\"initial\":  json_data}\n",
    "# conv layer\n",
    "shape = (32,5,5,3)\n",
    "conv1 = np.random.randint(low=-10, high=+10, size=shape).astype(np.float32, copy=False).flatten()\n",
    "\n",
    "data = {\n",
    "    \"v\": 1,\n",
    "    \"dim\": shape,\n",
    "    \"data\": conv1\n",
    "    }\n",
    "\n",
    "json_data = json.dumps(data, cls=NumpyArrayEncoder)\n",
    "\n",
    "layers_json[\"conv1\"] = json_data\n",
    "\n",
    "# conv layer\n",
    "shape = (32,5,5,32)\n",
    "conv2 = np.random.randint(low=-10, high=+10, size=shape).astype(np.float32, copy=False).flatten()\n",
    "\n",
    "data = {\n",
    "    \"v\": 1,\n",
    "    \"dim\": shape,\n",
    "    \"data\": conv2\n",
    "    }\n",
    "\n",
    "json_data = json.dumps(data, cls=NumpyArrayEncoder)\n",
    "\n",
    "layers_json[\"conv2\"] = json_data\n",
    "\n",
    "# fully connected\n",
    "\n",
    "shape = (1000, 14688)\n",
    "weights1 = np.random.randint(low=-10, high=+10, size=shape).astype(np.float32, copy=False).flatten()\n",
    "\n",
    "data = {\n",
    "    \"v\": 1,\n",
    "    \"dim\": shape,\n",
    "    \"data\": weights1\n",
    "}\n",
    "\n",
    "json_data = json.dumps(data, cls=NumpyArrayEncoder)\n",
    "\n",
    "layers_json[\"weights1\"] = json_data\n",
    "\n",
    "\n",
    "shape = (1000,)\n",
    "biases1 = np.random.randint(low=-10, high=+10, size=shape).astype(np.float32, copy=False).flatten()\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"v\": 1,\n",
    "    # ndarray can't take a single value, needs to be in json array\n",
    "    \"dim\": [1000],\n",
    "    \"data\": biases1\n",
    "}\n",
    "\n",
    "json_data = json.dumps(data, cls=NumpyArrayEncoder)\n",
    "\n",
    "layers_json[\"biases1\"] = json_data\n",
    "\n",
    "# fully connected\n",
    "shape = (5, 1000)\n",
    "weights2 = np.random.randint(low=-10, high=+10, size=shape).astype(np.float32, copy=False).flatten()\n",
    "\n",
    "data = {\n",
    "    \"v\": 1,\n",
    "    \"dim\": shape,\n",
    "    \"data\": weights2\n",
    "}\n",
    "\n",
    "json_data = json.dumps(data, cls=NumpyArrayEncoder)\n",
    "\n",
    "layers_json[\"weights2\"] = json_data\n",
    "\n",
    "shape = (5,)\n",
    "biases2 = np.random.randint(low=-10, high=+10, size=shape).astype(np.float32, copy=False).flatten()\n",
    "\n",
    "data = {\n",
    "    \"v\": 1,\n",
    "    # ndarray can't take a single value, needs to be in json array\n",
    "    \"dim\": [5],\n",
    "    \"data\": biases2\n",
    "}\n",
    "\n",
    "json_data = json.dumps(data, cls=NumpyArrayEncoder)\n",
    "\n",
    "layers_json[\"biases2\"] = json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "927a94a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer, json_data in layers_json.items():\n",
    "\n",
    "    with open(f\"../src/json/{layer}.json\", \"w\") as f:\n",
    "        f.write(json_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f4e31a",
   "metadata": {},
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a619bbbb-fad3-46ae-83b4-b74398cb953b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8388608"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8388608"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a1787ed-b448-40e2-96e7-7d597a4660e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5838826894760132"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4897963 / 8388608"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "33087999-ac7f-4ebd-b290-8dbbe3d0c51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(262144)/np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae322e92-7fcb-4270-9025-392773fc6da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4896000 * 3 / (14688 * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3078557e-adc4-4385-be93-567aa7d93e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.901244032467375"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(14688 * 800 / 3) / np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8316d646-b622-47b1-a58c-2ceb5de41c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5875200"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14688 * 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8abe8302-5958-427f-9453-7e2c4ff2cdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23500800"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14688 * 1600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "70387136-104a-4a18-9f20-72847ecee8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23407600"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "234076 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93298188-6ed4-4e9e-b3cc-20f9778e38bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17176301623.9445"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "output = [-6276474000, 8343393300, 8266027500, -7525360600, 7814137000]\n",
    "norm = np.linalg.norm(output)\n",
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1b09558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17176301623.9445"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.sqrt(6276474000**2 + 8343393300**2 + 8266027500**2 + 7525360600**2 + 7814137000**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9c85ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.36541475,  0.48575028,  0.48124606, -0.43812462,  0.45493711])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output/norm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
